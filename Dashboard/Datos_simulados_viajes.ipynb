{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importar librerías:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la cantidad de registros\n",
    "num_records = 10000000\n",
    "\n",
    "# Crear DataFrame con columnas vacías\n",
    "df = pd.DataFrame(columns=['service_type', 'year', 'month', 'day', 'day_of_week', 'hour', 'PULocationID', \n",
    "                           'DOLocationID', 'trip_miles', 'time_out', 'travel_time', 'fare_surcharges', \n",
    "                           'base_fare', 'service_number'])\n",
    "\n",
    "# Generar fechas aleatorias con horas entre 0 y 23\n",
    "start_date = datetime(2020, 1, 1)\n",
    "end_date = datetime(2023, 12, 31)\n",
    "date_list = [start_date + timedelta(days=random.randint(0, (end_date - start_date).days), hours=random.randint(0, 23)) for _ in range(num_records)]\n",
    "\n",
    "# Asignar fechas aleatorias al DataFrame\n",
    "df['date'] = date_list\n",
    "\n",
    "# Extraer datos de la fecha y eliminar la columna temporal\n",
    "df['year'] = df['date'].dt.year.astype('int16')\n",
    "df['month'] = df['date'].dt.month.astype('int32')\n",
    "df['day'] = df['date'].dt.day.astype('int32')\n",
    "df['day_of_week'] = df['date'].dt.day_name()\n",
    "df['hour'] = df['date'].dt.hour.astype('int64')\n",
    "df.drop(columns=['date'], inplace=True)\n",
    "\n",
    "# Generar PULocationID y DOLocationID únicos\n",
    "location_ids = list(range(1, 264))\n",
    "\n",
    "# Generar datos aleatorios para las columnas restantes\n",
    "df['PULocationID'] = np.random.choice(location_ids, num_records)\n",
    "df['DOLocationID'] = np.random.choice(location_ids, num_records)\n",
    "\n",
    "df['trip_miles'] = np.random.uniform(2, 55.5, num_records)\n",
    "df['travel_time'] = np.random.uniform(8, 120.5, num_records)\n",
    "df['fare_surcharges'] = np.random.uniform(0.5, 20.5, num_records)\n",
    "df['base_fare'] = np.random.uniform(0.5, 50.5, num_records)\n",
    "\n",
    "# Función para calcular el service_number según las condiciones dadas\n",
    "def calculate_service_number(row):\n",
    "    service_number = random.randint(20, 150)\n",
    "    if row['PULocationID'] in [ 4,  12,  13,  24,  41,  42,  43,  45,  48,  50,  68,  74,  75,\n",
    "        79,  87,  88,  90, 100, 103, 107, 113, 114, 116, 120, 125, 127,\n",
    "       128, 137, 140, 141, 142, 143, 144, 148, 151, 152, 153, 158, 161,\n",
    "       162, 163, 164, 166, 170, 186, 194, 202, 209, 211, 224, 229, 230,\n",
    "       231, 232, 233, 234, 236, 237, 238, 239, 243, 244, 246, 249, 261,\n",
    "       262, 263]:\n",
    "        service_number += 20\n",
    "    if 16 <= row['hour'] <= 20:\n",
    "        service_number += 20\n",
    "    return service_number\n",
    "\n",
    "# Aplicar la función a la columna service_number\n",
    "df['service_number'] = df.apply(calculate_service_number, axis=1)\n",
    "\n",
    "# Generar service_type según las condiciones dadas\n",
    "service_types = ['UberLyft'] * int(num_records * 0.7) + ['Yellow'] * int(num_records * 0.25) + ['Green'] * int(num_records * 0.05)\n",
    "random.shuffle(service_types)\n",
    "df['service_type'] = service_types\n",
    "\n",
    "# Generar time_out según las condiciones dadas\n",
    "df.loc[df['service_type'] == 'UberLyft', 'time_out'] = np.random.uniform(5, 35.5, len(df[df['service_type'] == 'UberLyft']))\n",
    "df.loc[df['service_type'] != 'UberLyft', 'time_out'] = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reducir tamaño con formato de número:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['trip_miles'] = df['trip_miles'].astype('float32')\n",
    "df['fare_surcharges'] = df['fare_surcharges'].astype('float32')\n",
    "df['base_fare'] = df['base_fare'].astype('float32')\n",
    "\n",
    "df['year'] = df['year'].astype('int16')\n",
    "df['month'] = df['month'].astype('int16')\n",
    "df['day'] = df['day'].astype('int16')\n",
    "df['hour'] = df['hour'].astype('int16')\n",
    "df['PULocationID'] = df['PULocationID'].astype('int16')\n",
    "df['DOLocationID'] = df['DOLocationID'].astype('int16')\n",
    "df['time_out'] = df['time_out'].astype('int16')\n",
    "df['travel_time'] = df['travel_time'].astype('int16')\n",
    "df['service_number'] = df['service_number'].astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000000 entries, 0 to 9999999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Dtype  \n",
      "---  ------           -----  \n",
      " 0   service_type     object \n",
      " 1   year             int16  \n",
      " 2   month            int16  \n",
      " 3   day              int16  \n",
      " 4   day_of_week      object \n",
      " 5   hour             int16  \n",
      " 6   PULocationID     int16  \n",
      " 7   DOLocationID     int16  \n",
      " 8   trip_miles       float32\n",
      " 9   time_out         int16  \n",
      " 10  travel_time      int16  \n",
      " 11  fare_surcharges  float32\n",
      " 12  base_fare        float32\n",
      " 13  service_number   int16  \n",
      "dtypes: float32(3), int16(9), object(2)\n",
      "memory usage: 438.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo Parquet comprimido se ha guardado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "# Guardar el DataFrame combinado en un archivo Parquet comprimido\n",
    "pq.write_table(pa.Table.from_pandas(df), 'Servicios_Agrupados.parquet', compression='gzip')\n",
    "\n",
    "print(\"El archivo Parquet comprimido se ha guardado exitosamente.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
